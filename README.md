# ğŸ–Œï¸ MNIST Digit Classifier (ONNX Runtime Web)

An interactive browser demo where you can **draw a digit (0â€“9)** on a canvas and instantly get predictions using a **tiny PyTorch CNN** exported to **ONNX**. The model runs entirely *clientâ€‘side* with [onnxruntimeâ€‘web](https://onnxruntime.ai/) (WebGPU/WASM) â€” no server required.

---

## âœ¨ Features
- ğŸ¨ **Canvas Drawing** â€“ mouse & touch support with adjustable brush.
- ğŸ” **Instant Prediction** â€“ 0â€“9 classification with probability bars.
- ğŸ–¼ï¸ **28Ã—28 Preview** â€“ see exactly what the model sees.
- âš¡ **Lightweight Models** â€“ `INT8` / `FP16` / `FP32` (all < 1 MB).
- ğŸŒ **Static Hosting** â€“ works on GitHub Pages or any static host.

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ index.html              # UI + inference (runs fully in-browser)
â”œâ”€â”€ train.py                # PyTorch training & ONNX export script
â”œâ”€â”€ mnist_tiny.pt           # Trained PyTorch weights
â”œâ”€â”€ mnist_tiny_fp32.onnx    # Full precision ONNX
â”œâ”€â”€ mnist_tiny_fp16.onnx    # Half precision ONNX
â”œâ”€â”€ mnist_tiny_int8.onnx    # Quantized INT8 ONNX
â””â”€â”€ README.md               # This README (Markdown-safe)
```

---

## ğŸš€ Run the Demo (Frontend)
1. Place `index.html` and the `.onnx` models in the same folder.
2. Open `index.html` in your browser, or publish via **GitHub Pages**.
3. Draw a digit â†’ click **Predict** â†’ see the result!

> **Tip:** On GitHub Pages, keep model paths relative. If you use a `models/` folder, update the paths in `index.html` accordingly.

---

## ğŸ› ï¸ Train & Export (PyTorch â†’ ONNX)
1. Install requirements:
   ```bash
   pip install torch torchvision onnx onnxconverter-common onnxruntime onnxruntime-tools
   ```
2. Train & export:
   ```bash
   python train.py
   ```
   This will:
   - Train a tiny CNN on MNIST.
   - Save PyTorch weights (`mnist_tiny.pt`).
   - Export ONNX in FP32, FP16, and INT8 formats.

---

## ğŸ“¸ Demo Preview
_Add a GIF or screenshot of the demo in action here._

---

## ğŸ§© Tech Stack
- **PyTorch** â€“ training & export
- **ONNX** â€“ interoperable model format
- **onnxruntimeâ€‘web** â€“ browser inference (WebGPU/WASM)
- **Vanilla HTML/CSS/JS** â€“ clean interactive UI

---

## ğŸ“ˆ Extensions
- Replace MNIST with **Fashionâ€‘MNIST**.
- Fineâ€‘tune **MobileNetV3â€‘Small** for a small custom dataset (<10 MB).
- Deploy multiple models and add a dropdown to switch between them.
- Improve UI with animations, themes, and probability charts.

---

## ğŸ“œ License
MIT â€” free to fork and modify.

> **Why you saw raw HTML earlier:** GitHub READMEs (Markdown) **sanitize** tags like `<head>`, `<style>`, and `<title>`. If you paste a full HTML page into `README.md`, those tags will show up as text. Use this Markdown version for GitHub, and keep any styled HTML as a separate file (e.g., `docs/readme.html`) if you want a themed page.
